{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "####  MICCAI_BraTS_2018_Data 数据集说明\n",
    "\n",
    "- BraTS 数据集是脑肿瘤分割比赛数据集，brats 2018中的训练集( training set) 有285个病例，每个病例有四个模态(t1、t2、flair、t1ce)，需要分割三个部分：whole tumor(WT), enhance tumor(ET), and tumor core(TC)\n",
    "\n",
    "- t1、t2、flair、t1ce可以理解为核磁共振图像的四个不同纬度信息，每个序列的图像shape为（155,240,240）\n",
    "\n",
    "- 目标是分割出三个label。对应医学中的三个不同肿瘤类型\n",
    "\n",
    "#### 数据集介绍\n",
    "BraTs数据集类型为XX.nii.gz，分别对应t1、t2、flair、t1ce，seg，其中seg是分割图像。图像大小均为（155，240，240）"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 提取数据"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile \n",
    "dataset_path = \"./data/MICCAI_BraTS_2018_Data_Training.zip\"  # Replace with your dataset path\n",
    "zfile = zipfile.ZipFile(dataset_path)\n",
    "zfile.extractall()\n",
    "print(\"提取数据成功\")"
   ]
  },
  {
   "source": [
    "## 安装依赖"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1m\u001b[36mHGG\u001b[m\u001b[m               brats_2018.ipynb  survival_data.csv\n\u001b[1m\u001b[36mLGG\u001b[m\u001b[m               \u001b[1m\u001b[36mdata\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": [
    "# venv\n",
    "# !python3 -m venv venv\n",
    "# !source venv/bin/active\n",
    "# !pip install -r requirements.txt\n",
    "\n",
    "# conda\n",
    "!conda env create -f enviroment.yml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk  # For loading the dataset\n",
    "import numpy as np  # For data manipulation\n",
    "import glob  # For populating the list of files\n",
    "from scipy.ndimage import zoom  # For resizing\n",
    "import re  # For parsing the filenames (to know their modality)"
   ]
  },
  {
   "source": [
    "## 数据预处理"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_path):\n",
    "    \"\"\"\n",
    "    Reads a .nii.gz image and returns as a numpy array.\n",
    "    \"\"\"\n",
    "    return sitk.GetArrayFromImage(sitk.ReadImage(img_path))\n",
    "\n",
    "def resize(img, shape, mode='constant', orig_shape=(155, 240, 240)):\n",
    "    \"\"\"\n",
    "    Wrapper for scipy.ndimage.zoom suited for MRI images.\n",
    "    \"\"\"\n",
    "    assert len(shape) == 3, \"Can not have more than 3 dimensions\"\n",
    "    factors = (\n",
    "        shape[0]/orig_shape[0],\n",
    "        shape[1]/orig_shape[1], \n",
    "        shape[2]/orig_shape[2]\n",
    "    )\n",
    "    \n",
    "    # Resize to the given shape\n",
    "    return zoom(img, factors, mode=mode)\n",
    "\n",
    "def preprocess(img, out_shape=None):\n",
    "    \"\"\"\n",
    "    Preprocess the image.\n",
    "    Just an example, you can add more preprocessing steps if you wish to.\n",
    "    \"\"\"\n",
    "    if out_shape is not None:\n",
    "        img = resize(img, out_shape, mode='constant')\n",
    "    \n",
    "    # Normalize the image\n",
    "    mean = img.mean()\n",
    "    std = img.std()\n",
    "    return (img - mean) / std\n",
    "\n",
    "def preprocess_label(img, out_shape=None, mode='nearest'):\n",
    "    \"\"\"\n",
    "    Separates out the 3 labels from the segmentation provided, namely:\n",
    "    GD-enhancing tumor (ET — label 4), the peritumoral edema (ED — label 2))\n",
    "    and the necrotic and non-enhancing tumor core (NCR/NET — label 1)\n",
    "    \"\"\"\n",
    "    ncr = img == 1  # Necrotic and Non-Enhancing Tumor (NCR/NET)\n",
    "    ed = img == 2  # Peritumoral Edema (ED)\n",
    "    et = img == 4  # GD-enhancing Tumor (ET)\n",
    "    \n",
    "    if out_shape is not None:\n",
    "        ncr = resize(ncr, out_shape, mode=mode)\n",
    "        ed = resize(ed, out_shape, mode=mode)\n",
    "        et = resize(et, out_shape, mode=mode)\n",
    "\n",
    "    return np.array([ncr, ed, et], dtype=np.uint8)"
   ]
  },
  {
   "source": [
    "## 加载数据"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of files for all modalities individually\n",
    "t1 = glob.glob('*GG/*/*t1.nii.gz')\n",
    "t2 = glob.glob('*GG/*/*t2.nii.gz')\n",
    "flair = glob.glob('*GG/*/*flair.nii.gz')\n",
    "t1ce = glob.glob('*GG/*/*t1ce.nii.gz')\n",
    "seg = glob.glob('*GG/*/*seg.nii.gz')  # Ground Truth"
   ]
  },
  {
   "source": [
    "Parse all the filenames and create a dictionary for each patient with structure:\n",
    "\n",
    "{<br />\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;'t1': _<path to t1 MRI file&gt;_,<br/>\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;'t2': _<path to t2 MRI&gt;_,<br />\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;'flair': _<path to FLAIR MRI file&gt;_,<br />\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;'t1ce': _<path to t1ce MRI file&gt;_,<br />\n",
    "    &nbsp;&nbsp;&nbsp;&nbsp;'seg': _<path to Ground Truth file&gt;_,<br />\n",
    "}<br />"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile('.*_(\\w*)\\.nii\\.gz')\n",
    "\n",
    "data_paths = [{\n",
    "    pat.findall(item)[0]:item\n",
    "    for item in items\n",
    "}\n",
    "for items in list(zip(t1, t2, t1ce, flair, seg))]"
   ]
  },
  {
   "source": [
    "## 装载数据到 Numpy 数组"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (4, 80, 96, 64)\n",
    "output_channels = 3\n",
    "data = np.empty((len(data_paths[:4]),) + input_shape, dtype=np.float32)\n",
    "labels = np.empty((len(data_paths[:4]), output_channels) + input_shape[1:], dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Progress: [=========================](100 %)"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Parameters for the progress bar\n",
    "total = len(data_paths[:4])\n",
    "step = 25 / total\n",
    "\n",
    "for i, imgs in enumerate(data_paths[:4]):\n",
    "    try:\n",
    "        data[i] = np.array([preprocess(read_img(imgs[m]), input_shape[1:]) for m in ['t1', 't2', 't1ce', 'flair']], dtype=np.float32)\n",
    "        labels[i] = preprocess_label(read_img(imgs['seg']), input_shape[1:])[None, ...]\n",
    "        \n",
    "        # Print the progress bar\n",
    "        print('\\r' + f'Progress: '\n",
    "            f\"[{'=' * int((i+1) * step) + ' ' * (24 - int((i+1) * step))}]\"\n",
    "            f\"({math.ceil((i+1) * 100 / (total))} %)\",\n",
    "            end='')\n",
    "    except Exception as e:\n",
    "        print(f'Something went wrong with {imgs[\"t1\"]}, skipping...\\n Exception:\\n{str(e)}')\n",
    "        continue"
   ]
  },
  {
   "source": [
    "## 构建模型"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}